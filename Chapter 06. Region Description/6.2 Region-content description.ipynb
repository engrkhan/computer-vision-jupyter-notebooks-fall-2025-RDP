{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.2 Region-content description\n",
    "\n",
    "Unlike shape description techniques, which work with regions' contours, region-content description focuses on characterizing the content of segmented regions through their distribution in the image, their textures, etc. Regarding textures, it gives us information about the spatial arrangement of color or intensities in an image or selected region of an image. Textures can be used to help in segmentation or classification of images. Notice that these methods doesn't require binary images as input. \n",
    "\n",
    "This notebook covers different region-content description techniques:\n",
    "\n",
    "- 2D image moments (section 6.2.1)\n",
    "- Hu moments (section 6.2.2)\n",
    "- Image histogram moments (section 6.2.3.1)\n",
    "- Co-ocurrence matrices (section 6.2.3.2)\n",
    "\n",
    "\n",
    "## Problem context - Car plates\n",
    "\n",
    "In this notebook, our task is twofold!\n",
    "\n",
    "### Number-plate detection for UMA\n",
    "\n",
    "<img src=\"./images/access_system.png\" width=\"400\">$\\\\[5pt]$\n",
    "\n",
    "Basically, we have to continue with our number-plate detection work looking for a way to obtain a feature vector that distinguishes each character in a Spanish car plate. In this notebok we will try more advanced methods, like **image moments** or **Hu moments**.\n",
    "\n",
    "### Identification of the State of a license plate state\n",
    "\n",
    "An American company contacted us for developing a **texture description method** that describes **a license plate according to its State of origin** instead of the characters appearing. As you may know, USA uses a different license plates for each state in the country:$\\\\[5pt]$\n",
    "\n",
    "<img src=\"./images/usa_plates.jpg\" width=\"600\">\n",
    "\n",
    "You will use some region description methods applied to this problem like **co-ocurrence matrices** or **image histogram moments**. Again, your task is to develop a method returning a feature vector that allows for the identification of the State of origin of such license plates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.rcParams['figure.figsize'] = (15.0, 8.0)\n",
    "from scipy import stats \n",
    "\n",
    "images_path = './images/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2.1 Image moments\n",
    "\n",
    "An **image moment** (2D-moment) is weighted average (or moment) of the intensity of the pixels in the image/region, or a function combining other moments. Moments usually have some attractive property or interpretation, and they can work in both grayscale and color images. There are 3 main types of moments:\n",
    "\n",
    "- **Non-central moments:**$\\\\[3pt]$\n",
    "\n",
    "$\\hspace{2cm}m_{ij} = \\sum_{y=1}^{cols}\\sum_{x=1}^{rows}x^i y^j I(x,y)$\n",
    "\n",
    "- **Central moments:**\n",
    "\n",
    "  $\\hspace{1.2cm}\\mu_{ij} = \\sum_{y=1}^{cols}\\sum_{x=1}^{rows}(x-\\overline{x})^i (y-\\overline{y})^j I(x,y)$ \n",
    "  $\\\\[2pt]$<br />\n",
    "  where: <br />\n",
    "    - $\\left(\\overline{x},\\overline{y}\\right) = \\left(\\frac{m_{10}}{m_{00}} ,\\frac{m_{01}}{m_{00}} \\right)$ is the centroid of the region $\\\\[3pt]$\n",
    "    - $I(x,y)$ means the intensity of the pixel in the $(x, y)$ coordinates of image $I$.\n",
    " \n",
    "  When dealing with big images/regions, it is possible to save some computation time computing the central moments using the non-central ones:\n",
    "\n",
    "$\n",
    "\\hspace{2cm}\\mu_{00} = m_{00} \\equiv \\mu \\\\\n",
    "\\hspace{2cm}\\mu_{01} = 0 \\\\\n",
    "\\hspace{2cm}\\mu_{10} = 0 \\\\\n",
    "\\hspace{2cm}\\mu_{20} = m_{20} - \\mu \\overline{x}^2\\\\\n",
    "\\hspace{2cm}\\mu_{11} = m_{11} - \\mu \\overline{xy}\\\\\n",
    "\\hspace{2cm}\\mu_{02} = m_{02} - \\mu \\overline{y}^2\\\\\n",
    "\\hspace{2cm}\\mu_{30} = m_{30} - 3m_{20} \\overline{x} + 2 \\mu \\overline{x}^3 \\\\\n",
    "\\hspace{2cm}\\mu_{21} = m_{21} - m_{20} \\overline{y} - 2m_{11} \\overline{x} + 2\\mu \\overline{x}^2\\overline{y} \\\\\n",
    "\\hspace{2cm}\\mu_{12} = m_{12} - m_{02} \\overline{x} - 2m_{11} \\overline{y} + 2\\mu \\overline{y}^2\\overline{x}\\\\\n",
    "\\hspace{2cm}\\mu_{03} = m_{03} - 3m_{02} \\overline{y} + 2 \\mu \\overline{y}^3\\\\[3pt] \n",
    "$\n",
    "\n",
    "- **Scale invariant moments:**$\\\\[3pt]$\n",
    "\n",
    "$\\hspace{2cm} \\eta_{ij} = \\mu_{ij}\\ /\\ \\mu_{00}^{1+((i+j)/2)}$\n",
    "\n",
    "$\\hspace{2cm}$ where $i + j \\ge 2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=\"orange\">OpenCV pill</font>\n",
    "    \n",
    "OpenCV defines a method for computing some central, non-central and scale-invariant moments called [`cv2.moments()`](https://docs.opencv.org/4.2.0/d3/dc0/group__imgproc__shape.html#ga556a180f43cab22649c23ada36a8a139), which gets:\n",
    "\n",
    "- working with intensity images: a contour (array of 2D points) delimiting the segmented regions.\n",
    "- working with grayscale images: the image itself.\n",
    "\n",
    "This function returns a dictionary containing those moments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<span style=\"color:green\"><b><i>ASSIGNMENT 1: Computing image moments</i></b></span>**\n",
    "\n",
    "**What to do?** Your first tasks is to complete the method `image_moments()`, which applies the previously mentioned [`cv2.moments()`](https://docs.opencv.org/4.2.0/d3/dc0/group__imgproc__shape.html#ga556a180f43cab22649c23ada36a8a139) to a binary image (e.g. thresholded numbers of a plate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignment 1\n",
    "def image_moments(region):\n",
    "    \"\"\" Compute moments of the region in a binary image.   \n",
    "    \n",
    "        Args:\n",
    "            region: Binary image\n",
    "                    \n",
    "        Returns: \n",
    "            moments: dictionary containing all moments of the region\n",
    "    \"\"\"   \n",
    "    \n",
    "    # Get external contour\n",
    "    \n",
    "    \n",
    "    # Compute moments\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use next code to **test if the results are correct**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = np.array([[255,255,255,255,255],[255,0,0,0,255],[255,0,0,255,255],[255,0,255,255,255],[0,0,255,255,255]], dtype=np.uint8)\n",
    "moments = image_moments(region)\n",
    "\n",
    "# Round moments for visualization matters\n",
    "for k, v in moments.items():\n",
    "    moments[k] = round(v,2)\n",
    "\n",
    "print(moments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>**Expected output  </font> (using `CHAIN_APPROX_NONE`):**\n",
    "\n",
    "    {'m00': 5.0, 'm10': 14.67, 'm01': 12.0, 'm20': 48.17, 'm11': 37.0, 'm02': 36.17, 'm30': 163.4, 'm21': 119.17, 'm12': 111.13, 'm03': 116.0, 'mu20': 5.14, 'mu11': 1.8, 'mu02': 7.37, 'mu30': -8.07, 'mu21': -6.99, 'mu12': -3.6, 'mu03': -6.16, 'nu20': 0.21, 'nu11': 0.07, 'nu02': 0.29, 'nu30': -0.14, 'nu21': -0.13, 'nu12': -0.06, 'nu03': -0.11}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invariance analysis \n",
    "\n",
    "Image moments could be good descriptors for addressing the problem posed by UMA. We could compute the moments of a segment region and use them as feature vector. Also, as $i$ and $j$ in the previous equations can take any integer, we could have a feature vector of any desired length.\n",
    "\n",
    "Our only problem is that the results have to be (at least) position and scale invariants, because a car be stopped closer or further away from the camera (rotation is not that important).\n",
    "\n",
    "To check if these moments have such invariances, you are going to compute the moments of a scaled and rotated region. To visually check the results, we are going to use bar charts, showing the moments for the original, rotated and scaled images, which should look like this:\n",
    "\n",
    "<img src=\"./images/moments.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<span style=\"color:green\"><b><i>ASSIGNMENT 2: Checking invariances</i></b></span>**\n",
    "\n",
    "Complete the method `compare_moments()`, which takes a list of labels for the bar chart and three lists containing the moments of a region, and its rotated and scaled versions. Then, it plots the chart bar previously showed.\n",
    "\n",
    "For the plot you can use `plt.bar(labels,values)`, where `labels` is a list of strings (e.g. `keys` of the dictionary of moments) and `values` a list of numbers (e.g. `values` of such dictionary). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignment 2\n",
    "def compare_moments(labels, moments, moments_rotated, moments_scaled):\n",
    "    \"\"\" Plot a bar chart comparing the three input moment arrays  \n",
    "    \n",
    "        Args:\n",
    "            labels: Labels of the bar chart\n",
    "            moments: list containing moments of a original region\n",
    "            moments_rotated: list containing moments of the original region, but previously rotated\n",
    "            moments_scaled: list containing moments of the original region, but previously scaled\n",
    "    \"\"\" \n",
    "    \n",
    "    # Show original moments\n",
    "    \n",
    "\n",
    "    # Show rotated moments\n",
    "    \n",
    "\n",
    "    # Show scaled moments\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to separately analyze the invariance of the the **non-central** (first 10 values of moment dictionary), **central** (following 7) and **scale-invariant** (last 7) moments.\n",
    "\n",
    "Let's start with the **Non-central moments**.\n",
    "\n",
    "*Hint: You can rotate a numpy array using [np.rot90](https://docs.scipy.org/doc/numpy/reference/generated/numpy.rot90.html) and scale an image using [cv2.resize](https://docs.opencv.org/4.2.0/da/d54/group__imgproc__transform.html#ga47a974309e9102f5f08231edc7e7529d), although there are many more options.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read binary image and compute moments\n",
    "\n",
    "\n",
    "# Rotate image and compute moments\n",
    "\n",
    "\n",
    "# Resize image and compute moments\n",
    "\n",
    "\n",
    "# Compare results for non-central moments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\"><b><i>Thinking about it (1)</i></b></font>\n",
    "\n",
    "Now, **answer the following questions:**\n",
    "\n",
    "- Are these moments invariant to rotation?\n",
    "\n",
    "    <p style=\"margin: 4px 0px 6px 5px; color:blue\"><i>Your answer here!</i></p>\n",
    "    \n",
    "- Are these moments invariant to scale?\n",
    "\n",
    "    <p style=\"margin: 4px 0px 0px 5px; color:blue\"><i>Your answer here!</i></p>   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's continue with **central moments**!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare results for central moments\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\"><b><i>Thinking about it (2)</i></b></font>\n",
    "\n",
    "Now, **answer the following questions:**\n",
    "\n",
    "- Are these moments invariant to rotation?\n",
    "\n",
    "    <p style=\"margin: 4px 0px 6px 5px; color:blue\"><i>Your answer here!</i></p>\n",
    "    \n",
    "- Are these moments invariant to scale?\n",
    "\n",
    "    <p style=\"margin: 4px 0px 0px 5px; color:blue\"><i>Your answer here!</i></p>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we conclude with **scale-invariant moments**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare results for scale-invariant moments\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\"><b><i>Thinking about it (3)</i></b></font>\n",
    "\n",
    "Now, **answer the following questions:**\n",
    "\n",
    "- Are these moments invariant to rotation?\n",
    "\n",
    "    <p style=\"margin: 4px 0px 6px 5px; color:blue\"><i>Your answer here!</i></p>\n",
    "    \n",
    "- Are these moments invariant to scale?\n",
    "\n",
    "    <p style=\"margin: 4px 0px 0px 5px; color:blue\"><i>Your answer here!</i></p>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2.2 Hu moments\n",
    "\n",
    "**Hu moments** (published in 1962 by Ming-Kuei Hu) are a set of 7 particular moments calculated using scale-invariant. Concretely, they are computed using following equations:\n",
    "\n",
    "$\n",
    "\\hspace{2cm}v_{1} = \\eta_{20} + \\eta_{02} \\\\\n",
    "\\hspace{2cm}v_{2} = (\\eta_{20} - \\eta_{02}) + 4\\eta_{11}^2 \\\\\n",
    "\\hspace{2cm}v_{3} = (\\eta_{20} - 3\\eta_{12})^2 + (3\\eta_{21} - \\eta_{03})^2 \\\\\n",
    "\\hspace{2cm}v_{4} = (\\eta_{30} + \\eta_{12})^2 + (\\eta_{21} + \\eta_{03})^2\\\\\n",
    "\\hspace{2cm}v_{5} = (\\eta_{30}-3\\eta_{12})(\\eta_{30}+\\eta_{12})[(\\eta_{30}+\\eta_{12})^2 -3(\\eta_{21}+\\eta_{03})^2] + (3\\eta_{21}-\\eta_{03})(\\eta_{21}+\\eta_{03})[3(\\eta_{30}+\\eta_{12})^2-(\\eta_{21} + \\eta_{03})^2]\\\\\n",
    "\\hspace{2cm}v_{6} = (\\eta_{20}-\\eta_{02})[(\\eta_{30}+\\eta_{12})^2 -(\\eta_{21}-\\eta_{03})^2 + 4\\eta_{11} (\\eta_{30}+\\eta_{12})(\\eta_{21}+\\eta_{03})] \\\\\n",
    "\\hspace{2cm}v_{7} = (3\\eta_{21}-\\eta_{03})(\\eta_{30}+\\eta_{12})[(\\eta_{30}+\\eta_{12})^2-3(\\eta_{30}+\\eta_{12})^2]+(\\eta_{30}-3\\eta_{12})(\\eta_{21}+\\eta_{03})[3(\\eta_{30}+\\eta_{12})^2-(\\eta_{21}+\\eta_{03})^2]\\\\\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=\"orange\">OpenCV pill</font>\n",
    "\n",
    "OpenCV provides a method to retrieve the Hu moments, called (wait for it...) [`cv2.moments()`](https://docs.opencv.org/4.2.0/d3/dc0/group__imgproc__shape.html#ga556a180f43cab22649c23ada36a8a139)!. This method takes as input the dictionary of moments returned by `cv2.moments`. Recall that the scale-invariant moments used for their computation are the `nuij` moments in the dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<span style=\"color:green\"><b><i>ASSIGNMENT 3: Exploring Hu moments invariances</i></b></span>**\n",
    "\n",
    "Previously, we tested the invariances of non-central, central and scale-invariant moments. Now, **we are interested in checking the invariances of the Hu moments**, so we can verify if they are more suitable for the UMA parking problem. \n",
    "\n",
    "For that, use your brand-new `compare_moments()` function in the same way as in the previous exercises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Assignment 3\n",
    "\n",
    "# Read binary image and compute Hu moments\n",
    "\n",
    "\n",
    "# Rotate image and compute Hu moments\n",
    "\n",
    "\n",
    "# Resize image and compute Hu moments\n",
    "\n",
    "\n",
    "\n",
    "# Compare results for Hu moments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\"><b><i>Thinking about it (4)</i></b></font>\n",
    "\n",
    "Now, **answer the following questions:**\n",
    "\n",
    "- Are these moments invariant to rotation?\n",
    "\n",
    "    <p style=\"margin: 4px 0px 6px 5px; color:blue\"><i>Your answer here!</i></p>\n",
    "    \n",
    "- Are these moments invariant to scale?\n",
    "\n",
    "    <p style=\"margin: 4px 0px 0px 5px; color:blue\"><i>Your answer here!</i></p>  \n",
    "    \n",
    "- Now that you can deal with different ways to describe a binary region, **what method would you use** for the UMA parking problem? **Why?**\n",
    "\n",
    "    <p style=\"margin: 4px 0px 0px 5px; color:blue\"><i>Your answer here!</i></p> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2.3 Texture\n",
    "\n",
    "While the previous techniques are useful for describing the distribution of the regions over the image. There is another brunch of algorithms that pursuit the description of regions by **characterizing the texture of the pixels they enclose**. Such methods measure the spatial arrangement of the colors/intensities in a region, providing information about their smoothness, coarseness, and regularity. In this way, if a region does not present changes in intensity, we say that it is a untextured region.\n",
    "\n",
    "<img src=\"./images/examples_of_different_textures.png\" width=\"700\"/>\n",
    "\n",
    "Usually, texture descriptors have spatial (position, orientation and scale) and radiometric (contrast and brightness) invariance.\n",
    "\n",
    "- 1D moments of the histogram, and\n",
    "- Gray Level Co-Occurrence Matrix (GLCM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.3.1 1D moments of histogram\n",
    "\n",
    "The **central moments of the histogram** of the pixels within the region statistically describes the frequency of their intensities. They permit us to compactly describe the region through a feature vector containing a few features. They are computed using the equation: $\\\\[5pt]$\n",
    "\n",
    "$\\hspace{2cm} \\mu_n = \\sum_{i=0}^{255} (z_i - \\overline{z})^n h(z_i)$\n",
    "\n",
    "where $h(z_i)$ represents the value stored in the histogram $h(\\cdot)$ for the intensity $z_i$. Keep in mind that:\n",
    "\n",
    "$\n",
    "\\hspace{2cm} \\mu_0=\\mu_1=0 \\\\ \n",
    "\\hspace{2cm} \\mu_2: \\text{variance (contrast)} \\\\\n",
    "\\hspace{2cm} \\mu_3: \\text{histogram (skew)} \\\\\n",
    "\\hspace{2cm} \\mu_4: \\text{histogram uniformity} \\\\\n",
    "$\n",
    "\n",
    "However, they have a serious drawback: they don't encode pattern structures, so different textures may have similar histograms:\n",
    "\n",
    "<img src=\"./images/patterns.png\" width=\"800\"/>\n",
    "\n",
    "Nevertheless, they can be a good option depending on the application, so do not underestimate them!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<span style=\"color:green\"><b><i>ASSIGNMENT 4: Analyizing histograms</i></b></span>**\n",
    "\n",
    "In order to play a bit with these moments, we move to our second application: the state recognition in USA car plates. Two examples of such license plates: $\\\\[5pt]$\n",
    "\n",
    "<img src=\"./images/idaho.jpg\" width=\"300\" align=\"left\"/>\n",
    "<img src=\"./images/nevada.jpg\" width=\"300\" align=\"rigth\"/> $\\\\[5pt]$\n",
    "\n",
    "As we can see, the main difference between them is the texture in the plate background, as each state has a different one. Let's try 1D moments of the histogram for describing those textures!\n",
    "\n",
    "**Your first task** is to plot the histogram of the previous images: `nevada.jpg` and `hawaii.jpg`, and comment if you think that the shape of the histograms is enough to differentiate them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignment 4\n",
    "\n",
    "# Read images\n",
    "\n",
    "\n",
    "# Show first one histogram\n",
    "\n",
    "\n",
    "# And the second one!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's complete the method `histogram_moments()` that implements the equation computing the central moments of the histogram shown above. This method takes as input:\n",
    "\n",
    "- an image, and \n",
    "- the number of moments to be calculated\n",
    "\n",
    "and returns an array containing those moments of the image's histogram.\n",
    "\n",
    "*Tip: the 1D central moment of order `k` can be calculed using [`stats.moment()`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.moment.html) (although it is easy to get them from scratch)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogram_moments(image,k):\n",
    "    \"\"\" Compute central moments of the histogram of an image.   \n",
    "    \n",
    "        Args:\n",
    "            image: input image\n",
    "            k: number of moments to compute\n",
    "                    \n",
    "        Returns: \n",
    "            histogram_moments: array containing the histogram moments\n",
    "    \"\"\"   \n",
    "    \n",
    "    \n",
    "    # Compute histogram\n",
    "    \n",
    "\n",
    "    # Compute moments\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the next code to **test if the results are correct**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = np.array([[10,60,20],[60,22,74],[72,132,2]], dtype=np.uint8)\n",
    "\n",
    "moments = histogram_moments(image,6)\n",
    "\n",
    "print(moments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>**Expected output: </font>**\n",
    "\n",
    "    [1.  0.  0.04173279  0.05414879  0.08191809  0.13725665]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Invariance analysis\n",
    "\n",
    "Now that we can obtain the first `k` moments of an image histogram, we are going to see if this method is invariant to scale and rotation. As in the UMA parking problem, our solution must be scale invariant, so let's check if it is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<span style=\"color:green\"><b><i>ASSIGNMENT 5: Checking the invariance of 1D moments</i></b></span>**\n",
    "\n",
    "**What to do?** Check if **the first six 1D moments** of the histogram of an image, a rotated version of it, and a scaled version, are the same. Use [`np.array_equal()`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.array_equal.html) for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignment 5\n",
    "\n",
    "# Read image and compute histogram moments\n",
    "\n",
    "\n",
    "# Rotate image and compute histogram moments\n",
    "\n",
    "    \n",
    "# Resize image and compute histogram moments\n",
    "\n",
    "\n",
    "# Compare results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\"><b><i>Thinking about it (5)</i></b></font>\n",
    "\n",
    "Now, **answer the following questions:**\n",
    "\n",
    "- **It is invariant to rotation?** If not, how can we turn this method into it?\n",
    "\n",
    "    <p style=\"margin: 4px 0px 6px 5px; color:blue\"><i>Your answer here!</i></p>\n",
    "    \n",
    "- It is invariant to scale? **If not, how can we turn this method into it?**\n",
    "\n",
    "    <p style=\"margin: 4px 0px 0px 5px; color:blue\"><i>Your answer here!</i></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.3.2 Co-ocurrence matrix\n",
    "\n",
    "Another technique also obtaining a statistical representation of the texture within a region is the **co-ocurrence matrix**, a square matrix $A(i,j)$ in which:\n",
    "\n",
    "- $i$ and $j$ represent intensity values (e.g. 0 to 255). \n",
    "- The entry $a_{ij}$ indicates how many times the intensity $i$ co-occurs with intensity $j$ in some designated spatial relationships $P$ (texture pattern). \n",
    "- $P$ is given by a displacement vector $d = [dr, dc]$, where $dr$ and $dc$ are the displacement in rows and columns, respectively.\n",
    "\n",
    "<img src=\"./images/co-ocu.png\" width=\"650\"/>\n",
    "\n",
    "The issue with this approach is how to select the appropriate displacement $d$. Once the co-ocurrence matrix of a region has been computed, a number of features can be extracted from it:\n",
    "\n",
    "- **Maximum probability:** gives us the strongest response to the texture pattern $P$$ \\\\[1pt]$\n",
    "\n",
    "$\\hspace{2cm} max_{ij}\\ c_{ij}$\n",
    "\n",
    "- **Energy:** mínimum when all the entries $c_{ij}$ are identical (máximum uniformity)$ \\\\[1pt]$\n",
    "\n",
    "$\\hspace{2cm} \\sum_{i=0}^{255}\\sum_{j=0}^{255}\\ c_{ij}^2$\n",
    "\n",
    "- **Entropy:** measure randomness. Maximum value when all the entries $c_{ij}$ are identical (máximum entropy  $\\rightarrow$ mínimum mínima energía)$ \\\\[1pt]$\n",
    "\n",
    "$\\hspace{2cm} -\\sum_{i=0}^{255}\\sum_{j=0}^{255}\\ c_{ij} \\ logc_{ij}$\n",
    "\n",
    "- **Order k central moment**$ \\\\[1pt]$\n",
    "\n",
    "$\\hspace{2cm} \\sum_{i=0}^{255}\\sum_{j=0}^{255}\\ (i-j)^k \\ c_{ij}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<span style=\"color:green\"><b><i>ASSIGNMENT 6: Computing co-ocurrence matrices</i></b></span>**\n",
    "\n",
    "Let's implement the method `co_ocurrence_matrix_features()`, which has to compute the normalized co-ocurrence matrix of `image` using the displacement vector `[dr,dc]` and normalizes it, obtaining `C(i,j)`. Note that `dr` and `dc` may take positive or negative values. Thereby, it takes as inputs:\n",
    "- an image, \n",
    "- a 2-size displacement vector, and \n",
    "- a number of central moment to compute. \n",
    "\n",
    "and returns:\n",
    "- a feature vector with size 3 + `n_moments` being: [`max_prob`, `energy`, `entropy`, `moments` (optional)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignment 6\n",
    "\n",
    "def co_ocurrence_matrix_features(image, d, n_moments):\n",
    "    \"\"\" Compute features from a image using a co-ocurrence matrix.   \n",
    "    \n",
    "        Args:\n",
    "            image: Binary image\n",
    "            d: displacement vector\n",
    "            n_moments: number of moment to be computed\n",
    "                    \n",
    "        Returns: \n",
    "            features: feature vector\n",
    "    \"\"\"   \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Compute image ranges to iterate from displacement vector\n",
    "    \n",
    "\n",
    "    # Compute co-ocurrence matrix    \n",
    "\n",
    "\n",
    "    # Normalize co-ocurrence matrix\n",
    "    \n",
    "\n",
    "    # Maximum probability\n",
    "    \n",
    "\n",
    "    # Energy\n",
    "    \n",
    "\n",
    "    # Entropy\n",
    "    \n",
    "\n",
    "    # Central moments\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the next code to **test if the results are right**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "image = np.array([[10,60,20],[60,22,74],[72,132,2]], dtype=np.uint8)\n",
    "\n",
    "features = co_ocurrence_matrix_features(image,d=[1,-2],n_moments=4)\n",
    "\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>**Expected output: </font>**\n",
    "\n",
    "    [0.5  0.5  0.693  1.  -19.  802.  -31996.  ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<span style=\"color:green\"><b><i>ASSIGNMENT 7: Studying the invariance of co-occurence matrices</i></b></span>**\n",
    "\n",
    "Compare the results returned by `co_ocurrence_matrix_features()` when using the original image `hawaii.jpg`, with those returned by a rotated or scaled version of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignment 7\n",
    "\n",
    "# Read image and compute co-occurence matrix features\n",
    "\n",
    "\n",
    "# Rotate image and compute co-occurence matrix features\n",
    "\n",
    "    \n",
    "# Resize image and compute co-occurence matrix features\n",
    "\n",
    "\n",
    "# Compare results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\"><b><i>Thinking about it (6)</i></b></font>\n",
    "\n",
    "Now, **answer the following question:**\n",
    "\n",
    "- **Compare the invariance of each feature in the feature vector** and **comment why it is invariant or not to rotation and scale.**\n",
    "\n",
    "    <p style=\"margin: 4px 0px 6px 5px; color:blue\"><i>Your answer here!</i></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Awesome! This was a laborious and dense notebook, but you carried it through to the end!\n",
    "\n",
    "In this notebook you have learned:\n",
    "\n",
    "- how to compute non-central, central, scale-invariant and Hu moments for describing a region, and apply them to the plate number recognition problem.\n",
    "\n",
    "- how to describe textures using 1D moments of the histogram and co-ocurrence matrices, using them in the context of the state identification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra\n",
    "\n",
    "Usually, the co-ocurrence matrices **of the image rotated** 45, 90, and 135 degrees are also calculated. **What do you think this is due to?**  \n",
    "\n",
    "**Implement this new procedure** for co-ocurrence matrices and then, check again the invariances. **What happened?**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "382.85px",
    "left": "1390px",
    "right": "20px",
    "top": "120px",
    "width": "443px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
