{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11.1 Image stitching\n",
    "\n",
    "Image stitching (Mosaicing) is considered as an active research area in computer vision and computer graphics. Image stitching is concerned with combining two or more images of the same scene into one high resolution image which is called panoramic image. The basic geometry of the problem is well understood, and consists of estimating a $3\\times3$ camera matrix or homography for each image.\n",
    "\n",
    "In this practise, we will explain how a complex image stitching application works and you will develop a basic one. You will need to understand how feature matching (chapter 04) and homographies (chapter 08) work in order to complete this notebook.\n",
    "\n",
    "<img src=\"./images/stitching5_res.jpg\" width=\"800\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.rcParams['figure.figsize'] = (16.0, 16.0)\n",
    "images_path = './images/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenCV Stitcher class\n",
    "\n",
    "OpenCV defines the class [Stitcher](https://docs.opencv.org/4.2.0/d2/d8d/classcv_1_1Stitcher.html), which implements a complex image stitching tool. The next code shows an example of how two or more images can be stitched using that class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "images.append(cv2.imread(\"./images/stitching2_1.jpg\"))\n",
    "images.append(cv2.imread(\"./images/stitching2_2.jpg\"))\n",
    "images.append(cv2.imread(\"./images/stitching2_3.jpg\"))\n",
    "\n",
    "stitcher = cv2.Stitcher.create(mode=0)\n",
    "_, panorama = stitcher.stitch(images)\n",
    "\n",
    "cv2.imwrite(\"./images/stitching2_res.jpg\",panorama)\n",
    "panorama = cv2.cvtColor(panorama,cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(panorama)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But... **how does it works?**\n",
    "\n",
    "Basically, for achieving image stitching, we have 2 main steps:\n",
    "\n",
    "- **Finding and matchign features.** The first step in panorama stitching is to extract and match features. For this we can use Harris + NCC, ORB, ...\n",
    "\n",
    "- **Image Matching.**  In this step, we can use [RANSAC, LMEDS, ...](https://docs.opencv.org/4.2.0/d9/d0c/group__calib3d.html#ga4abc2ece9fab9398f2e560d53c8c9780) methods to estimate the Homographies of the best matched pairs, with these homographies, images can be aligned. And images aligned this way is called **local registration**.\n",
    "\n",
    "However, we can enhance resulting images using some extra methods that complex tools usually implement. We can see the whole stitching module pipeline that is implemented in openCV in the following figure:\n",
    "\n",
    "<img src=\"./images/pipeline.png\" width=\"800\" />\n",
    "\n",
    "Using the Stitcher class, it's possible to configure/remove some steps, i.e. adjust the stitching pipeline according to the particular needs. You can get information about extra steps for a complete image stitching tool [here](https://sites.google.com/site/ritpanoramaapp/project-stage-iii).\n",
    "\n",
    "**Your task in this notebook** is to stitch example images `stitching_1.jpg` and `stitching_2.jpg`. You can see how openCV achieve it using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "images.append(cv2.imread(\"./images/stitching_1.jpg\"))\n",
    "images.append(cv2.imread(\"./images/stitching_2.jpg\"))\n",
    "\n",
    "\n",
    "stitcher = cv2.Stitcher.create(mode=0)\n",
    "_, panorama = stitcher.stitch(images)\n",
    "\n",
    "cv2.imwrite(\"./images/stitching_res.jpg\",panorama)\n",
    "panorama = cv2.cvtColor(panorama,cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(panorama)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\"><b><i>ASSIGNMENT 1: Developing our own stitcher</i></b></span>\n",
    "\n",
    "As we said above, we have to stitch images `stitching_1.jpg` and `stitching_2.jpg` with our own code, avoiding the class `cv2.Stitcher` in order to learn how it can be done from scratch.\n",
    "\n",
    "In a nutshell, what you should do is **finding matching points in both images** and then **finding the homography that transforms the points in the second image over their matchings in the first one**, or the other way around (you may use `cv2.RANSAC` for finding the homography). Resulting image should look like this (as you can see, only the second image has been transformed):\n",
    "\n",
    "<img src=\"./images/stitching_manual.png\" width=\"600\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
