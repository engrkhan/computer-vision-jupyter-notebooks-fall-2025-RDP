{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.3 Binomial distribution Naive Bayes Classifier\n",
    "\n",
    "In the previous notebook we appied a Maximum Log-Likelihood estimation ($d_k(x) = ln\\ p(\\mathbf{x}/C_k)$) on features that follow a normal distribution. In this notebook we will use as well a Maximum Log-Likelihood estimation but **now the variables follow a binomial distribuion** (variables are either $1$ or $0$). \n",
    "\n",
    "As we are using a **naive** Bayes classifier, variables are again assumed **independent**:\n",
    "\n",
    "$$P(x_i \\cap x_j) = P(x_i)p(x_j) \\; \\forall i,j$$\n",
    "\n",
    "In this notebook we will learn how a naive Bayes classifier can be trained (section 7.3.1) and tested (section 7.3.2) using binomial variables.\n",
    "\n",
    "## Problem contex - Digit recognition\n",
    "\n",
    "> Digit recognition system is the working of a machine to **train itself or recognizing the digits** from different sources like emails, bank cheque, papers, images, etc. and in different real-world scenarios for online handwriting recognition on computer tablets or system, recognize **number plates of vehicles**, processing bank cheque amounts, numeric entries in forms filled up by hand (say â€” tax forms) and so on.\n",
    "\n",
    "For completing our plate detector and recognition system, we are going to learn how to construct a digit recognition system (can be generalized for all plate possible characters) usign a naive Bayes classifier.\n",
    "\n",
    "<img src=\"./images/plateRecognition.png\" width=\"400\"/>\n",
    "\n",
    "For this problem we need a set of digit images that will be used as training dataset for our classifier. For car plate recognition we would have to classify digits and letter. For simplify this, we are going to use only digit images (only 10 possible classes). You can find provided images in `./images/train_binary/imagen{0-9}_{1-500}.png`, having 500 images for each digit.\n",
    "\n",
    "*Note that images contains handwritten digits instead of plate ones, but it's the same procedure.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.rcParams['figure.figsize'] = (16.0, 8.0)\n",
    "\n",
    "images_path = './images/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3.1 Training a naive Bayes classifier (binomial distribution)\n",
    "\n",
    "We will follow the same procedure than in the previous notebook, but adapted to binomial distribution. First, we need to remember how the discriminant function of a Bayesian classifier is created:$\\\\[10pt]$\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "&d_k(x) &= P(C_k/\\mathbf{x}) = \\frac{p(\\mathbf{x}/C_k)P(C_k)}{P(\\mathbf{x})}\\\\\n",
    "\\xrightarrow{P(\\mathbf{x})\\text{ is a constant value }\\forall k} \\hspace{0.2cm}&d_k(x) &= p(\\mathbf{x}/C_k)P(C_k)\\\\[7pt]\n",
    "\\xrightarrow{\\text{ ln doesn't alter maximum }} \\hspace{0.2cm} &d_k(x) &= lnp(\\mathbf{x}/C_k) + lnP(C_k)\\\\[7pt]\n",
    "\\xrightarrow{\\text{If } P(C_k) = P(C_j)\\; \\forall \\ j,k }\\hspace{0.2cm} &d_k(x) &= lnp(\\mathbf{x}/C_k)\n",
    "\\end{eqnarray}\n",
    "\\\\[8pt]$$\n",
    "\n",
    "For this problem, we have $28x28$ pixels images, and each pixel is a feature that can be either $0$ or $1$:\n",
    "\n",
    "$$\\mathbf{x} = [x_1 \\; x_2 \\; \\ldots \\; x_f \\; \\ldots \\; x_{28x28}]$$\n",
    "\n",
    "And the probability of a pixel $x_f$ belongs to a class $C_i$ is:\n",
    "\n",
    "$$p(x_f/C_i) = (p_f^i)^{x_f} *  (1 - p_f^i)^{(1 - x_f)}$$\n",
    "\n",
    "Being $p_f^i$ the probability that $x_f = 1$ if $\\mathbf{x} \\in C_i$.  \n",
    "\n",
    "Our features are independent (naive Bayes classifier), so we can multiply all probaiblities:$\\\\[5pt]$\n",
    "\n",
    "$$p(\\mathbf{x}/C_i) = \\Pi_{f=1}^n p(x_f/C_i) = \\Pi_{f=1}^n (p_f^i)^{x_f}*(1 - p_f^i)^{(1 - x_f)}$$\n",
    "\n",
    "Finally, for obtaining the discriminant function, we apply the logaritm:$\\\\[7pt]$\n",
    "\n",
    "$$ln\\ p(\\mathbf{x}/C_i) = \\Sigma_{f=1}^n [x_f \\cdot ln(p_f^i) + (1- x_f) \\cdot ln\\ (1-p_f^i)] = \\Sigma_{f=1}^n x_f \\cdot ln\\ \\frac{p_f^i}{1-p_f^i} + \\Sigma_{f=1}^n ln\\ (1-p_f^i)$$\n",
    "\n",
    "$$d_i(x) = ln \\ p(\\mathbf{x}/C_i) + ln \\ P(C_i) = \\underbrace{ln \\ P(C_i) + \\Sigma_{f=1}^n ln\\ (1-p_f^i)}_{w_{n+1}^i} + \\Sigma_{f=1}^n x_f \\cdot \\underbrace{ln\\ \\frac{p_f^i}{1-p_f^i}}_{w_f^i}$$\n",
    "\n",
    "As we can see, the function is lineal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<span style=\"color:green\"><b><i>ASSIGNMENT 1a</i></b></span>**\n",
    "\n",
    "**Setting up the data**\n",
    "\n",
    "The first step for training the classifier is preparing the images, this is done vectorizing each image. **Our task** is to construct a matrix containing all the images data (`./images/train_binary/imagen{0-9}_{1-500}.png`), this array will have 3 dimensions $(n\\_pixels, n\\_images, n\\_classes)$. Each column of the array contains a vectorized version of the corresponding image (the are `m_images` columns for `n_images` images). In the third column we have the classes (we have 10 possible classes {0-9}).\n",
    "\n",
    "<img src=\"./images/vectorize.png\" width=\"700\"/>\n",
    "\n",
    "Read all images (500 images for each digit) and obtain the mentioned matrix storing all data. Images are grayscale, you will have to segment them first using openCV in order to follow a binomial distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training\n",
    "\n",
    "# Initialize matrix\n",
    "\n",
    "\n",
    "# For each class\n",
    "\n",
    "    # For each image in the class\n",
    "    \n",
    "        # Read the image\n",
    "        \n",
    "        # Binarize it\n",
    "        \n",
    "        # Reshape it\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<span style=\"color:green\"><b><i>ASSIGNMENT 1b</i></b></span>**\n",
    "\n",
    "**Computing probabilities**\n",
    "\n",
    "Now, we will compute the probabilities matrix that allows us to compute the weights:\n",
    "\n",
    "$$d_i(x) = ln \\ p(\\mathbf{x}/C_i) + ln \\ P(C_i) = \\underbrace{ln \\ P(C_i) + \\Sigma_{f=1}^n ln\\ (1-p_f^i)}_{w_{n+1}^i} + \\Sigma_{f=1}^n x_f \\cdot \\underbrace{ln\\ \\frac{p_f^i}{1-p_f^i}}_{w_f^i}$$\n",
    "\n",
    "In this case, the weights are constructed from probabilities ($p_f^i$). Each variable $p_f^i$ contains the probability that $x_f = 1$ if $\\mathbf{x} \\in C_i$. For binomial distribution, computing the probabilities is straightforward. We just have to count the number of times that each pixel is `1` in each class, and divide it by the number of imaged used:\n",
    "\n",
    "$$p_{f}^i = \\frac{1}{N}\\Sigma_{k=1}^{N}x_{f,k}^{i}$$$\\\\[3pt]$\n",
    "\n",
    "*Regarding to our problem, $N=500$ as we have $500$ images for each class and the range of $f$ is $[0-783]$*.\n",
    "\n",
    "<img src=\"./images/probabilities.png\" width=\"700\"/>$\\\\[2pt]$\n",
    "\n",
    "**What to do?** Construct a 2D matrix **containing all the probabilities** ($matrix[f,i] = p_f^i$). Then, **unvectorize the probabilities** in the matrix (2D $\\rightarrow$ 3D), constructing **heatmaps**, which are images where each pixel contains its own probability. Finally, **plot the heatmaps** in order to **check** if we are in a good way:  \n",
    "\n",
    "<img src=\"./images/heatmaps.png\" width=\"700\"/>\n",
    "\n",
    "*Tip: try to use [np.sum](https://numpy.org/doc/stable/reference/generated/numpy.sum.html) for computing the probaiblities in order to avoid loops, which are usually slower (check the `axis` argument).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute probabilities\n",
    "\n",
    "\n",
    "# Reshape to obtain heatmaps\n",
    "\n",
    "\n",
    "# Plot heatmaps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<span style=\"color:green\"><b><i>ASSIGNMENT 1c</i></b></span>**\n",
    "\n",
    "**Computing weights**\n",
    "\n",
    "As you know, once we obtain the weights of the discriminant function, we can compute the discriminant functions and then classify new images. So, this is the last training step.\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "w_f^i &=& ln\\ \\frac{p_f^i}{1-p_f^i}\\\\[5pt]\n",
    "w_{n+1}^i &=& ln\\ P(C_k) + \\Sigma_{f=1}^n ln(1- p_f^i)\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "Note that we can't neither divide by 0 nor compute the logarithm of 0. If we want to compute the weights, we should **previously replace 0 and 1 probabilities for close numbers** (e.g. 0.0001 and 0.9999), this can be done using [np.where](https://numpy.org/doc/1.18/reference/generated/numpy.where.html).  \n",
    "\n",
    "Again, as we don't have any prior information about the occurences of each class, the prior probability $P(C_k)$ should be $1/n\\_classes$ for each class $k$.\n",
    "\n",
    "**What to do?** Construct a 2D matrix containing the weights of the classifier.\n",
    "\n",
    "*For applying the natural logarithm to all the elements of a matrix, you can use [np.log](https://numpy.org/doc/1.18/reference/generated/numpy.log.html?highlight=log#numpy.log).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Weight calculation\n",
    "\n",
    "# Replace 0 and 1 values\n",
    "\n",
    "\n",
    "# Initialize matrix\n",
    "\n",
    "\n",
    "# Compute weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3.2 Testing a naive Bayes classifier (binomial distribution)\n",
    "\n",
    "Once we have the weights $w_{n+1}^i$ and $w_f^i$, we can evaluate the discriminant functions $d_i(x) \\; (i=0,1,\\ldots,9)$ for each vector $\\mathbf{x}$ (a new vectorized image that have not been used in training phase).\n",
    "\n",
    "$$d_i(\\mathbf{x}) = w_{n+1}^i + \\Sigma_{f=0}^{783}w_f^i \\cdot x_f \\quad i = 0,\\ldots, 9$$\n",
    "\n",
    "We will have 10 outputs, the results of the discriminant functions (one per class). As we are estimating the **maximum log-likelihood**, the assigned class will be maximum distriminant function.\n",
    "\n",
    "### **<span style=\"color:green\"><b><i>ASSIGNMENT 2</i></b></span>**\n",
    "\n",
    "For this exercise, we provide the numPy matrix `digitos.npy` located at `./test_binary/`. It is a 1D matrix containing 50 digits between 0 and 9 that are the classes of the images `./test_binary/timage{1-50}`. **Your task** is to classify those 50 images and check if the output of your classifier match with the actual class (contained in `digitos.npy`). In this way, we can estimate how good is our classifier.\n",
    "\n",
    "*If you trained your classifier with the provided images, you should have 41/50 hits, or a 82% of accuracy.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Testing\n",
    "\n",
    "# Load provided matrix\n",
    "\n",
    "\n",
    "# Classify each testing image\n",
    "\n",
    "    # Read the image\n",
    "    \n",
    "    # Binarize it\n",
    "    \n",
    "    # Vectorize it\n",
    "    \n",
    "    # Evaluate the discriminant functions\n",
    "    \n",
    "    # Get the maximum\n",
    "    \n",
    "# Print the accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<span style=\"color:green\"><b><i>EXTRA: ASSIGNMENT 3</i></b></span>**\n",
    "\n",
    "You can also test your classifier with your own images, try to write a digit in a paper and make a photo with your phone. You will need some preprocessing first in order to preparing the image as a feature vector $\\mathbf{x}$.$\\\\[5pt]$\n",
    "\n",
    "<img src=\"./images/testcamera.jpeg\" width=\"300\"/>$\\\\[5pt]$\n",
    "\n",
    "First, you will need to segment the region of interest (crop the digit). Then, you will have to resize the image to a $28\\times28$ image (classifier input), you can use [cv2.resize](https://docs.opencv.org/4.2.0/da/d54/group__imgproc__transform.html#ga47a974309e9102f5f08231edc7e7529d) for that. Finally, binarize and vectorize the image so it can be used as input for the classifier. Follow the steps done in *assignment 2* for classify the image and show the results!\n",
    "\n",
    "<img src=\"./images/extra_example.png\" width=\"700\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Testing with our own image\n",
    "\n",
    "# Read image and convert it to grayscale\n",
    "\n",
    "\n",
    "# Crop ROI\n",
    "\n",
    "\n",
    "# Binarize it\n",
    "\n",
    "\n",
    "# Reshape the image\n",
    "\n",
    "\n",
    "# Evaluate the discriminant functions\n",
    "\n",
    "    \n",
    "# Get the maximum\n",
    "\n",
    "\n",
    "# Plot the results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Excellent! You learned how to:\n",
    "\n",
    "- construct and train an efficient naive Bayes classifier for binary images\n",
    "- test and obtain the accuracy of the classifier\n",
    "- classify images, in the context of handwritten digits or car plates characters (just changing the training dataset)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "531.85px",
    "left": "1529px",
    "right": "20px",
    "top": "115px",
    "width": "319px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
